{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heddaenger/FakeNews/blob/main/Logreg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61Wd-0yeS7nc"
      },
      "outputs": [],
      "source": [
        "from typing import Callable # Extra: read about type hints: https://docs.python.org/3/library/typing.html\n",
        "import warnings\n",
        "\n",
        "\n",
        "\n",
        "# needs to run before importing pandas. Silences a harmless pandas FutureWarning\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "import pandas as pd\n",
        "import spacy\n",
        "import nltk\n",
        "from nltk.corpus import stopwords as nltk_stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "from scipy.sparse import csr_matrix\n",
        "import plotly.express as px\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, precision_recall_curve, f1_score\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load data\n",
        "class CSVLoader:\n",
        "    \"\"\" Load a CSV file into a pandas DataFrame.\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def fetch(path : str, **kwargs) -> pd.DataFrame:\n",
        "        return pd.read_csv(path, **kwargs)\n",
        "\n",
        "    def load(self, path : str, prep_func : Callable | None, **kwargs) -> pd.DataFrame:\n",
        "        data = self.fetch(path, **kwargs)\n",
        "        if isinstance(prep_func, Callable):\n",
        "            return prep_func(data)\n",
        "        return data"
      ],
      "metadata": {
        "id": "IbwHPDhhTpKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9wU1xwcTrNI",
        "outputId": "b3f5c59a-fa5a-43d9-fa9f-b5c3bd738d72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_label(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\" A data preparation function for the fake news dataset.\"\"\"\n",
        "    return (\n",
        "        df\n",
        "        .drop(columns=['Unnamed: 0'], errors='ignore')\n",
        "        .astype({\"text\": 'string', \"label\": 'category'})\n",
        "    )\n",
        "\n",
        "dataf = CSVLoader().load(\n",
        "    path='/content/drive/MyDrive/train.csv',\n",
        "    prep_func=preprocess_label\n",
        ")"
      ],
      "metadata": {
        "id": "iyoY3FqQTtpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_label(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\" A data preparation function for the fake news dataset.\"\"\"\n",
        "    return (\n",
        "        df\n",
        "        .drop(columns=['Unnamed: 0'], errors='ignore')\n",
        "        .astype({\"text\": 'string'})\n",
        "    )\n",
        "\n",
        "test_raw = CSVLoader().load(\n",
        "    path='/content/drive/MyDrive/test.csv',\n",
        "    prep_func=preprocess_label\n",
        ")"
      ],
      "metadata": {
        "id": "EsLqjpOmV7Kt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = dataf.dropna()"
      ],
      "metadata": {
        "id": "Y9eFMGpBTw1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows with missing values and reset the index\n",
        "df_unprocessed = dataf.dropna().reset_index(drop=True)"
      ],
      "metadata": {
        "id": "rLzwBMieTz80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_unprocessed =df_unprocessed.head(2000)"
      ],
      "metadata": {
        "id": "ov_AfnlqT2xT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_unprocessed.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfRJ66A6T4f9",
        "outputId": "876df066-139f-4ca4-bde2-c63e7fe20200"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-9qC56IT6DS",
        "outputId": "c8c6c189-d1ad-4f38-d370-bf46a0c39fa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id        0\n",
              "title     0\n",
              "author    0\n",
              "text      0\n",
              "label     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testdf = test_raw.dropna()"
      ],
      "metadata": {
        "id": "1W1VUxCoWtRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_unprocessed = testdf.dropna().reset_index(drop=True)"
      ],
      "metadata": {
        "id": "bm55xtOaWzF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_unprocessed = test_unprocessed.head(2000)"
      ],
      "metadata": {
        "id": "_-NRPLUWW8or"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_unprocessed.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jn2ZuK5NXPi3",
        "outputId": "fc8c08f4-f633-4ab3-bc4e-4791dd5bc8b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_unprocessed.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNrV6zEIXJ8l",
        "outputId": "78c980a8-e3d3-4098-c084-b33a1167f438"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id        0\n",
              "title     0\n",
              "author    0\n",
              "text      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = test_unprocessed.drop(['author', 'title', 'id'], axis=1)"
      ],
      "metadata": {
        "id": "qFV4w9WlYpGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "VDxvHmMsgpCd",
        "outputId": "64938eab-adf5-43ac-c2fd-109f3b88bbb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text\n",
              "0  PALO ALTO, Calif.  —   After years of scorning...\n",
              "1  Videos #NoDAPL: Native American Leaders Vow to...\n",
              "2  If at first you don’t succeed, try a different...\n",
              "3  42 mins ago 1 Views 0 Comments 0 Likes 'For th...\n",
              "4  Sunday on NBC’s “Meet the Press,” House Minori..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-63bf387f-6bbd-484e-bef4-7951bb0af152\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PALO ALTO, Calif.  —   After years of scorning...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Videos #NoDAPL: Native American Leaders Vow to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>If at first you don’t succeed, try a different...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>42 mins ago 1 Views 0 Comments 0 Likes 'For th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sunday on NBC’s “Meet the Press,” House Minori...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-63bf387f-6bbd-484e-bef4-7951bb0af152')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-63bf387f-6bbd-484e-bef4-7951bb0af152 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-63bf387f-6bbd-484e-bef4-7951bb0af152');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c9a19a29-4b93-4b4a-a5ef-72be6e9306ee\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c9a19a29-4b93-4b4a-a5ef-72be6e9306ee')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c9a19a29-4b93-4b4a-a5ef-72be6e9306ee button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_data",
              "summary": "{\n  \"name\": \"test_data\",\n  \"rows\": 2000,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1981,\n        \"samples\": [\n          \"The World Health Organization (WHO) have told scientists to stay silent on documents relating to the cancer-causing dangers associated with glyphosate. \\nVia YourNewsWire \\nIn a letter, officials from the International Agency for Research on Cancer (IARC) warned scientists against disclosing information from a 2015 study that suggests that Monsanto\\u2019s weedkiller Roundup is carcinogenic.\\nThe WHO\\u2019s International Agency for Research on Cancer (IARC) distributed a report in early 2015 calling the weed killer \\u201cprobably carcinogenic.\\u201d Makers of the product say the claim is false, citing their own research into the product.\\nSince then, several groups using Freedom of Information Laws have asked for documents related to how the IARC decision was made, including scientists on the panel that live and work in the U.S. at U.S. institutions. In response, the WHO said those documents pertaining to glyphosate research are private and its own property.\\nReuters reports some parties are considering a lawsuit seeking to clarify whether that\\u2019s the case and if it\\u2019s subject to U.S. FOIA laws. Glyphosate is the key ingredient of Roundup, which is sold by Monsanto.\\n\",\n          \"Evan Swarztrauber, communications director of TechFreedom, spoke with Breitbart News Daily SiriusXM host Alex Marlow on Friday about the FCC, net neutrality, and several other   topics under the Trump administration, as opposed to the Obama era. [Swarztrauber stressed that the big government,   mentality one usually associates with liberals and Democrats often confounded private sector efforts to advance Internet and broadband technology during the Obama administration.  \\u201cThere\\u2019s a lot that can be done\\u201d with the change in administration, suggested Swarztrauber. \\u201cAnd the FCC can play a positive role. It can be an ally to companies and consumers, rather than just trying to regulate everything. \\u201d Swarztrauber has high hopes for   FCC head Ajit Pai, whom many see as already moving ahead with Trump\\u2019s deregulatory agenda. Breitbart News Daily airs on SiriusXM Patriot 125 weekdays from 6:00 a. m. to 9:00 a. m. Eastern. \",\n          \"by Outis Philalithopoulos By Outis Philalithopoulos, who met an untimely end five years ago, and now \\u201cwears the chains he forged in life\\u201d as an economist. Previous events in this series led the ghost of Outis back to 1996. After meeting the first of three Spirits and being shown a series of sometimes unwelcome visions, Outis found himself alone. I thought about the people I had seen during my spectral journey. They seemed to think of themselves as liberals, even though they would be out of place among modern progressives. I toyed with an evolutionary explanation. There were things Brown didn\\u2019t understand about forceful communication, and things Franken didn\\u2019t understand about a lot of subjects, but maybe the two of them were \\u201cprimitive progressives,\\u201d who hadn\\u2019t yet developed into real progressives. Maybe if someone had just called them out, they would have understood, and grown. One thing Franken and Brown had in common is that they both came off as smarter than the people they criticized. To me, being progressive was basically about not being stupid, and so it was unsurprising that primitive progressives had also tried to show that they were intelligent. But to reach that end, Franken and Brown used different strategies. Franken seemed one of a group of 90s Democrats who saw themselves as having mastered the most defensible positions on each issue. Support of deficit reduction and trade pacts were orthodox positions of mainstream economics, and so for these liberals, there wasn\\u2019t any political problem here \\u2013 you just needed to say the correct answer as quickly as possible. For Brown, on the other hand, her self-confidence was tied more closely to her academic career, and to her ability to see around and behind \\u201cnarratives\\u201d that other people might believe in. What else brought the \\u201cwhipsmart\\u201d Democrats and the academic postmodernists together? Not much, as far as I could tell, except that they both disliked sounding too definite. In other words, they also had in common a sort of \\u201cpostmodern attitude.\\u201d I wondered if my generalizations about primitive progressives held more broadly. What else could I remember about liberals of the time? There was a lot said about self-esteem. One time in high school something bad happened and a teacher wanted us to hold hands, and talk and feel together \\u2013 or was that a movie? Regardless, many people did seemed to prize being non-judgmental. Wendy Brown had worried about whether some liberals genuinely believed in postmodernism, especially those trying to represent particular demographic groups. Even those writers, according to Brown, typically claimed to believe that culture was socially constructed, but they also wanted to privilege the perspectives of people who had suffered more, and treat their suffering as objectively real. Brown didn\\u2019t explain why this was supposed to be a problem, and clearly later progressives had realized that Brown was wrong to be so concerned. If primitive progressives had been a \\u201crainbow coalition\\u201d of disparate groups who didn\\u2019t have much in common besides smartness and a vague commitment to postmodernism, how were they able to work together at all? How had we managed to banish the specter of postmodernism, and build an unprecedented degree of cultural cohesion and confidence? A finger touched my shoulder. Michel had returned. \\u201cI know you are weary of my presence,\\u201d he began sympathetically, \\u201cand so I will speed you to the last clues I can provide.\\u201d \\u201cBut can we instead\\u2026\\u201d I began. Before I could finish my sentence, the horizon blurred and I found ourselves in a large lecture hall, surrounded by people who seemed very important, and somber. At the podium was a stern man in suit and tie. His voice rang through the hall: Something else died on Tuesday, in addition to thousands of innocent people. It was the doctrine of moral equivalency \\u2014 the idea that people everywhere are just like us, or can be made so by meeting their demands. These humanistic, \\u201ccan\\u2019t we all get along,\\u201d \\u201cprofiling potential terrorists is racism,\\u201d \\u201cwe\\u2019re all God\\u2019s children,\\u201d Kumbaya, \\u201call we\\u2019re saying is give peace a chance\\u201d moral equivalency equivocators will soon be back. They\\u2019ll try to wear down our resolve. They should be ignored. Evil exists. It must be opposed. If this is war, let\\u2019s start acting like it and tell America\\u2019s enemies that if they are so intent on seeing their God, we\\u2019ll help them get there. As for us, we intend to die of natural causes. The audience cheered. \\u201cI guess this is 9/11?\\u201d I said to Foucault. \\u201cTwo days later,\\u201d he concurred. \\u201cAnd this guy is some sort of rightwinger?\\u201d He nodded. \\u201cSyndicated columnist Cal Thomas.\\u201d A young, smartly dressed woman was speaking to her neighbor. \\u201cGuess what\\u2019s on the bestseller list right now?\\u201d Her somewhat older neighbor shook her head. \\u201c Quarterlife Crisis \\u2013 a book written by two twentysomethings bemoaning the,\\u201d and here her voice became brutally sarcastic, \\u2018 landmine period in our adult development during the transition from college graduation into the real world.\\u2019\\u201c \\u201cThe poor dears,\\u201d said the neighbor. \\u201cMany of them feel,\\u201d and here her voice took the same tone as it had before, \\u201c helpless, panicked, indecisive, and apprehensive . You know what this generation needs? A real crisis. And now\\u2026. we have one. Our generational wake-up call. Our bloody moment of shattered self-complacency.\\u201d \\u201cMichel, Michel,\\u201d I said, annoyed. \\u201cI get it. The Right was fixated on the idea that progressives lacked moral clarity. Whatever truth there was in that claim, it\\u2019s clearly false now. What I\\u2019d really like to know is\\u2026\\u201d But Foucault shook his head and put a finger to his lips. Again, the scene shifted. We were in another room, with another speaker and another audience. This venue, though, was rather small, and while some attendants looked rather professional, others were dressed informally. Foucault whispered to me, \\u201c2007.\\u201d The audience listened intently to the speaker. She exuded an infectious, intimate candor as she talked about Internet activism. You know what? Sometimes we\\u2019re very, very rude. I go right into the face of mainstream media writers\\u2019 faces and call them out. I\\u2019m right in there with the worst of them, foul-mouthed, vituperative, and personal. There\\u2019s a reason for that: it\\u2019s the only way to get their attention ! We have a beef \\u2013 and I maintain it\\u2019s legitimate and important. For years we\\u2019ve watched the mainstream media aid and abet the right wing to the point at which they behaved like a bunch of puerile cheerleaders for an absurd impeachment and stolen election. Iraq was the frosting on the cake. There\\u2019s no amount of polite discourse that\\u2019s going to shake up that comfortable relationship. And after Iraq, it\\u2019s become downright dangerous. Finally, a real progressive, I thought to myself. As she ended her speech, two men in expensive suits, with open collars, faced each other. \\u201cShe\\u2019s right, you know, and it\\u2019s not just the media,\\u201d one remarked. \\u201cNo shit,\\u201d the other seconded. \\u201cSay what you want about the Republicans, they know how to win. All we know how to do is lose.\\u201d The first shook his head in disgust. \\u201cThe whole Democratic Party has become a bunch of,\\u201d and he lowered his voice, \\u201cpussies.\\u201d I looked angrily at Foucault. He put a sympathetic hand on my shoulder. The second man also shook his head. \\u201cWe need to grow some balls.\\u201d He paused, then went on. \\u201cThe thing is, I know this sounds optimistic after the last couple decades, but I actually think some people are starting to get it.\\u201d \\u201cIt\\u2019s true,\\u201d the first acknowledged. \\u201cTake Rahm Emanuel. Someone tries to swift boat him, he swift boats them back. Some people don\\u2019t like him \\u2018cause he\\u2019s abrasive and says fuck a lot, but if you ask me, we need more people where you kinda feel like, this guy isn\\u2019t intimidated by Karl Rove.\\u201d \\u201cYeah, Rahm\\u2019s cool,\\u201d the second said. \\u201cWe just need to put ourselves out there more. Stop letting the Republicans paint us as weak. Stop accepting that they\\u2019re just going to get all the good donors.\\u201d \\u201cExactly,\\u201d the first said with some passion. \\u201cAnd it\\u2019s not like this means compromising our principles.\\u201d \\u201cOf course not,\\u201d snorted the second. \\u201cI mean, we have our convictions. We just need to be smarter.\\u201d \\u201cMichel,\\u201d I said with some heat. \\u201cif the point is supposed to be that in our efforts to stand up to the right wing, we became more like them, I have to say, I find the idea unpersuasive and offensive.\\u201d \\u201cWell\\u2026,\\u201d he began. I motioned him to silence. \\u201cI think it\\u2019s really not that complicated. With the rise of the Internet, it became easier for good ideas to circulate and harder for bad ideas to escape criticism. So of course we were able to stick up for the truth more vigorously, and be less wishy-washy than before. Sort of like how the printing press made the Reformation possible\\u2026\\u201d \\u201cI see!\\u201d he exclaimed, brightening. \\u201cYou cast yourself as one of the early Protestants, upholding a more rigorous standard of morality against the worldly and corrupt Catholics who preceded you. The Internet punishes tentativeness, just as the printing press made it so Erasmus\\u2019 skepticism could be pilloried by Luther in their debate on free will.\\u201d \\u201cUh\\u2026\\u201d I said, a little disoriented by his tendency to show off his erudition. \\u201cBut perhaps,\\u201d he mused, \\u201cif the earlier liberals are the medieval Catholic church, then you are the Counter-Reformation, strengthening the discipline of the Catholic faithful by imposing meticulous rules of self-examination and intensifying the obligation of confession?\\u201d That sounded less flattering. Michel frowned and took a step back. Some sort of invisible force was tugging on the back of his shirt. He turned to me and sighed. \\u201c D\\u00e9sol\\u00e9, but my time has grown very short.\\u201d I opened my mouth to say something, but Foucault, and the room from 2007, disappeared. In their place stood a bunny, looking me straight in the eye. * * * In the next episode, Outis journeys into a popular and widely praised artistic representation of modern liberal culture. Sources: Cal Thomas\\u2019 column from September 13, 2001 can be read here . The young woman attending his talk is based on Michelle Malkin, see her September 12 column . The Internet activist is based on Heather Digby Parton\\u2019s recollections of Netroots , with past tense changed to present. Foucault\\u2019s comments on the Counter-Reformation are loosely paraphrased from p. 19 of Discipline and Punish . His comments on the Reformation are not based on anything concrete in his writings, and hopefully he would not disagree too strongly with them. 0 0 0 0 0 0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Making the train/test split with unprocessed data (unvectorized and untokenized)\n",
        "(\n",
        "    X_train,\n",
        "    X_test,\n",
        "    y_train,\n",
        "    y_test\n",
        ") = train_test_split(\n",
        "    df_unprocessed['text'],\n",
        "    df_unprocessed['label'],\n",
        "    test_size=0.4, # toggle as needed\n",
        "    stratify=df_unprocessed[\"label\"],\n",
        "    random_state=42\n",
        "  )"
      ],
      "metadata": {
        "id": "XT4t058tUCHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking the distribution of real and fake news\n",
        "y_train.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmAK1As0UF1o",
        "outputId": "8f1b8a95-17ba-406c-f5d1-79bb2dff4dad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label\n",
              "0    677\n",
              "1    523\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Making the pipeline for logistic regression.\n",
        "logistic_pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer()),\n",
        "    ('logreg', LogisticRegression()),\n",
        "])\n",
        "\n",
        "# Defining the hyperparameters for the model to search through.\n",
        "parameters = {\n",
        "    'tfidf__max_df': (0.5, 0.75, 1.0),\n",
        "    'tfidf__ngram_range': [(1, 1), (1, 2)],  # unigrams or bigrams\n",
        "    'logreg__C': np.logspace(-4, 4, 20),\n",
        "    'logreg__penalty': ['l1', 'l2'],\n",
        "    'logreg__solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
        "}\n",
        "\n",
        "# Running the randomized search.\n",
        "random_search_logistic = RandomizedSearchCV(logistic_pipeline, parameters, n_iter=5, cv=5, verbose=1, random_state=42)\n",
        "\n",
        "# Fitting the model.\n",
        "random_search_logistic.fit(X_train, y_train)\n",
        "\n",
        "# Getting the best hyperparameters.\n",
        "best_parameters = random_search_logistic.best_estimator_.get_params()\n",
        "for param_name in sorted(parameters.keys()):\n",
        "    print(f\"{param_name}: {best_parameters[param_name]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWeaCrQbUJYW",
        "outputId": "45d85c0e-8d8c-41ac-b68a-d34fff1dacb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "5 fits failed out of a total of 25.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "5 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 405, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.92416667        nan 0.925      0.93416667 0.925     ]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logreg__C: 3792.690190732246\n",
            "logreg__penalty: l1\n",
            "logreg__solver: liblinear\n",
            "tfidf__max_df: 0.75\n",
            "tfidf__ngram_range: (1, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Making the new pipeline with the best parameters and fit the model to those.\n",
        "log_reg_tuned_pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(\n",
        "        max_df=best_parameters['tfidf__max_df'],\n",
        "        ngram_range=best_parameters['tfidf__ngram_range']\n",
        "    )),\n",
        "    ('logreg', LogisticRegression(\n",
        "        C=best_parameters['logreg__C'],\n",
        "        penalty=best_parameters['logreg__penalty'],\n",
        "        solver=best_parameters['logreg__solver']\n",
        "    )),\n",
        "])\n",
        "\n",
        "log_reg_tuned_pipeline.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "B-qReoe7ULtp",
        "outputId": "3b5e5658-424d-43f7-a602-0e7a3cd33c56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidf', TfidfVectorizer(max_df=0.75, ngram_range=(1, 2))),\n",
              "                ('logreg',\n",
              "                 LogisticRegression(C=3792.690190732246, penalty='l1',\n",
              "                                    solver='liblinear'))])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer(max_df=0.75, ngram_range=(1, 2))),\n",
              "                (&#x27;logreg&#x27;,\n",
              "                 LogisticRegression(C=3792.690190732246, penalty=&#x27;l1&#x27;,\n",
              "                                    solver=&#x27;liblinear&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer(max_df=0.75, ngram_range=(1, 2))),\n",
              "                (&#x27;logreg&#x27;,\n",
              "                 LogisticRegression(C=3792.690190732246, penalty=&#x27;l1&#x27;,\n",
              "                                    solver=&#x27;liblinear&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_df=0.75, ngram_range=(1, 2))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=3792.690190732246, penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting on the test set.\n",
        "y_pred_log_test = log_reg_tuned_pipeline.predict(X_test)\n",
        "y_pred_log_train = log_reg_tuned_pipeline.predict (X_train)\n",
        "\n",
        "# Evaluating the model and printing accuracy on train/test to check for overfitting.\n",
        "print(classification_report(y_test, y_pred_log_test, target_names=['real', 'fake']))\n",
        "print(\"Accuracy train:\", accuracy_score(y_train, y_pred_log_train))\n",
        "print(\"Accuracy test:\", accuracy_score(y_test, y_pred_log_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSXkMZyzUN5h",
        "outputId": "263c1115-23d9-423b-9184-177bff9c11da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        real       0.91      0.96      0.93       452\n",
            "        fake       0.94      0.87      0.90       348\n",
            "\n",
            "    accuracy                           0.92       800\n",
            "   macro avg       0.92      0.91      0.92       800\n",
            "weighted avg       0.92      0.92      0.92       800\n",
            "\n",
            "Accuracy train: 1.0\n",
            "Accuracy test: 0.92\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8re7-c2iN5V",
        "outputId": "e1b7f883-364f-4783-a1bd-8e76ebf899b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting on the test set.\n",
        "pred_log_final = log_reg_tuned_pipeline.predict(test_data)"
      ],
      "metadata": {
        "id": "LNFG0w5SZBNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = pd.DataFrame({\n",
        "    'Predictions': pred_log_final\n",
        "})"
      ],
      "metadata": {
        "id": "3lr4BqevZNnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting probability estimates for the predictions\n",
        "probabilities = log_reg_tuned_pipeline.predict_proba(test_data)[:, 1]  # Assuming class '1' probabilities\n",
        "\n",
        "# Creating a DataFrame to hold the test data identifiers, predictions, and probabilities\n",
        "results = pd.DataFrame({\n",
        "    'Predictions': pred_log_final,\n",
        "    'Probability': probabilities\n",
        "})\n",
        "\n",
        "# Save to CSV\n",
        "results.to_csv('enhanced_predictions.csv', index=False)"
      ],
      "metadata": {
        "id": "D0LSjZcvc14r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEV6HFG3g_2p",
        "outputId": "6fe4c260-cba5-4c9b-a431-f34c2b986ac9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the results to a new CSV file\n",
        "results.to_csv('predictions.csv', index=False)"
      ],
      "metadata": {
        "id": "PGbLgDqHZviX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1A49SBhuan-3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}